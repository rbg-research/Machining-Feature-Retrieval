{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'channels_last'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the necessary libraries\n",
    "\n",
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from model.resunet import ResUNetBN2C\n",
    "from util.visualization import get_colored_point_cloud_feature\n",
    "from numpy import linalg as LA\n",
    "from util.feature_extraction import stl2ply_convert, feature_extract\n",
    "from util.misc import sort_list, zero_pad\n",
    "from util.spp_layer import  SpatialPyramidPooling\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "import tensorflow.keras.backend as K\n",
    "K.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickling the features previously extracted\n",
    "\n",
    "with open(\"data/names_paths_features_featurenet.dat\", \"rb\") as f:\n",
    "    file_names, file_paths, features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 24\n",
      "\n",
      " Counter({'9_triangular_pocket': 1000, '20_v_circular_end_blind_slot': 1000, '11_circular_end_pocket': 1000, '4_rectangular_passage': 1000, '21_h_circular_end_blind_slot': 1000, '0_Oring': 1000, '16_2sides_through_step': 1000, '2_blind_hole': 1000, '23_6sides_pocket': 1000, '7_rectangular_through_slot': 1000, '6_triangular_through_slot': 1000, '17_slanted_through_step': 1000, '22_6sides_passage': 1000, '8_rectangular_blind_slot': 1000, '1_through_hole': 1000, '5_circular_through_slot': 1000, '3_triangular_passage': 1000, '15_rectangular_through_step': 1000, '19_round': 1000, '14_rectangular_blind_step': 1000, '18_chamfer': 1000, '13_circular_blind_step': 1000, '12_triangular_blind_step': 1000, '10_rectangular_pocket': 1000})\n"
     ]
    }
   ],
   "source": [
    "# Checking the number of classes and the data count\n",
    "families = Counter(file_names)\n",
    "print(\"Number of classes:\",len(families))\n",
    "print(\"\\n\",families)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f51e3d84040>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the distrubtion of feaure dimensions along all the 24 classes\n",
    "shape_list = list()\n",
    "for i in range(0,len(features)):\n",
    "    f = features[i]\n",
    "    shape_list.append(f.shape[0])\n",
    "xs = [x for x in range(len(shape_list))]\n",
    "plt.plot(xs,shape_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212\n"
     ]
    }
   ],
   "source": [
    "# Checking maximum feature dimension\n",
    "max_val=0\n",
    "\n",
    "for i in range(0,len(features)):\n",
    "    f = features[i]\n",
    "    max = np.maximum(f.shape[0],f.shape[1])\n",
    "    if(max > max_val):\n",
    "        max_val = max\n",
    "print(max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero padding all the vectors to max value\n",
    "def zero_pad(x):\n",
    "    shape_pad = max_val \n",
    "    x1 = np.zeros([shape_pad,32])\n",
    "    x1[:x.shape[0],:x.shape[1]] = x\n",
    "    return x1\n",
    "max_val = 240\n",
    "for j in range(0,len(features)):\n",
    "    z = zero_pad(features[j])\n",
    "    features[j] =z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "X = np.asarray(features)\n",
    "\n",
    "# one-hot encoding\n",
    "Y_set = set(file_names)\n",
    "Y_list = (list(Y_set))\n",
    "mapping = {}\n",
    "family = list()\n",
    "\n",
    "# 24 unique features\n",
    "for x in range(len(Y_list)):\n",
    "  mapping[Y_list[x]] = x\n",
    "\n",
    "# mapping to corresponding category\n",
    "for x in range(len(file_names)):\n",
    "  family.append(mapping[file_names[x]])\n",
    "\n",
    "Y = to_categorical(family)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5, random_state=1)\n",
    "# val,test = 0.5 x 0.3 = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convering to tensors\n",
    "x_train = tf.convert_to_tensor(x_train, dtype=None, dtype_hint=None, name=None)\n",
    "x_val = tf.convert_to_tensor(x_val, dtype=None, dtype_hint=None, name=None)\n",
    "x_test = tf.convert_to_tensor(x_test, dtype=None, dtype_hint=None, name=None)\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=None, dtype_hint=None, name=None)\n",
    "y_val = tf.convert_to_tensor(y_val, dtype=None, dtype_hint=None, name=None)\n",
    "y_test = tf.convert_to_tensor(y_test, dtype=None, dtype_hint=None, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping tensor for input to neural net\n",
    "\n",
    "x_train = tf.reshape(x_train, [len(x_train),max_val,32,1])\n",
    "x_val = tf.reshape(x_val, [len(x_val),max_val,32,1])\n",
    "x_test = tf.reshape(x_test, [len(x_test),max_val,32,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D, Activation, MaxPooling2D, Dense, Dropout\n",
    "\n",
    "\n",
    "# Minimizes Tensorflow Logging\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "NUM_CHANNELS = 1\n",
    "NUM_CLASSES = 24\n",
    "\n",
    "def makeModel():\n",
    "    model = Sequential()\n",
    "\n",
    "    # MODEL 1\n",
    "    # uses tensorflow ordering. Note that we leave the image size as None to allow multiple image sizes\n",
    "    model.add(Convolution2D(32, 3, NUM_CHANNELS, padding='same', input_shape=(max_val,32,1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(32, 3, NUM_CHANNELS, padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Convolution2D(64, 3, NUM_CHANNELS, padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, 3, NUM_CHANNELS, padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(SpatialPyramidPooling([1, 2, 4]))\n",
    "    model.add(Dense(NUM_CLASSES))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.executing_eagerly = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 240, 32, 32)       320       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 240, 32, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 240, 32, 32)       9248      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 240, 32, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 120, 16, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 120, 16, 64)       18496     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 120, 16, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 120, 16, 64)       36928     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 120, 16, 64)       0         \n",
      "_________________________________________________________________\n",
      "spatial_pyramid_pooling_1 (S (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                32280     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 24)                0         \n",
      "=================================================================\n",
      "Total params: 97,272\n",
      "Trainable params: 97,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=makeModel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.92750, saving model to model/pretrained/spp_featurenet2.h5\n",
      "1050/1050 - 13s - loss: 0.1514 - accuracy: 0.9355 - val_loss: 0.1629 - val_accuracy: 0.9275\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.92750 to 0.92778, saving model to model/pretrained/spp_featurenet2.h5\n",
      "1050/1050 - 13s - loss: 0.1288 - accuracy: 0.9446 - val_loss: 0.1695 - val_accuracy: 0.9278\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.92778 to 0.93194, saving model to model/pretrained/spp_featurenet2.h5\n",
      "1050/1050 - 13s - loss: 0.1214 - accuracy: 0.9477 - val_loss: 0.1548 - val_accuracy: 0.9319\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.93194 to 0.93250, saving model to model/pretrained/spp_featurenet2.h5\n",
      "1050/1050 - 13s - loss: 0.1156 - accuracy: 0.9504 - val_loss: 0.1563 - val_accuracy: 0.9325\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.93250 to 0.93500, saving model to model/pretrained/spp_featurenet2.h5\n",
      "1050/1050 - 13s - loss: 0.1136 - accuracy: 0.9522 - val_loss: 0.1554 - val_accuracy: 0.9350\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.93500\n",
      "1050/1050 - 13s - loss: 0.1065 - accuracy: 0.9524 - val_loss: 0.1674 - val_accuracy: 0.9331\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.93500\n",
      "1050/1050 - 13s - loss: 0.0960 - accuracy: 0.9580 - val_loss: 0.1716 - val_accuracy: 0.9344\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.93500 to 0.93917, saving model to model/pretrained/spp_featurenet2.h5\n",
      "1050/1050 - 13s - loss: 0.0921 - accuracy: 0.9604 - val_loss: 0.1510 - val_accuracy: 0.9392\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.93917\n",
      "1050/1050 - 13s - loss: 0.0901 - accuracy: 0.9622 - val_loss: 0.1627 - val_accuracy: 0.9308\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.93917 to 0.94139, saving model to model/pretrained/spp_featurenet2.h5\n",
      "1050/1050 - 13s - loss: 0.0854 - accuracy: 0.9648 - val_loss: 0.1518 - val_accuracy: 0.9414\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.94139\n",
      "1050/1050 - 13s - loss: 0.0815 - accuracy: 0.9663 - val_loss: 0.1773 - val_accuracy: 0.9414\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.94139 to 0.94333, saving model to model/pretrained/spp_featurenet2.h5\n",
      "1050/1050 - 13s - loss: 0.0763 - accuracy: 0.9673 - val_loss: 0.1700 - val_accuracy: 0.9433\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.94333 to 0.94361, saving model to model/pretrained/spp_featurenet2.h5\n",
      "1050/1050 - 13s - loss: 0.0730 - accuracy: 0.9689 - val_loss: 0.1617 - val_accuracy: 0.9436\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.94361 to 0.94556, saving model to model/pretrained/spp_featurenet2.h5\n",
      "1050/1050 - 13s - loss: 0.0738 - accuracy: 0.9695 - val_loss: 0.1544 - val_accuracy: 0.9456\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.94556\n",
      "1050/1050 - 13s - loss: 0.0714 - accuracy: 0.9710 - val_loss: 0.1663 - val_accuracy: 0.9414\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.94556\n",
      "1050/1050 - 13s - loss: 0.0741 - accuracy: 0.9698 - val_loss: 0.1759 - val_accuracy: 0.9433\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.94556\n",
      "1050/1050 - 13s - loss: 0.0622 - accuracy: 0.9727 - val_loss: 0.1718 - val_accuracy: 0.9428\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.94556\n",
      "1050/1050 - 13s - loss: 0.0643 - accuracy: 0.9730 - val_loss: 0.1742 - val_accuracy: 0.9389\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.94556\n",
      "1050/1050 - 13s - loss: 0.0679 - accuracy: 0.9733 - val_loss: 0.1696 - val_accuracy: 0.9400\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.94556\n",
      "1050/1050 - 13s - loss: 0.0649 - accuracy: 0.9732 - val_loss: 0.1605 - val_accuracy: 0.9447\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.94556 to 0.94611, saving model to model/pretrained/spp_featurenet2.h5\n",
      "1050/1050 - 13s - loss: 0.0567 - accuracy: 0.9776 - val_loss: 0.1761 - val_accuracy: 0.9461\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.94611\n",
      "1050/1050 - 13s - loss: 0.0579 - accuracy: 0.9767 - val_loss: 0.1974 - val_accuracy: 0.9428\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.94611\n",
      "1050/1050 - 13s - loss: 0.0663 - accuracy: 0.9728 - val_loss: 0.1781 - val_accuracy: 0.9442\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.94611\n",
      "1050/1050 - 13s - loss: 0.0561 - accuracy: 0.9765 - val_loss: 0.1887 - val_accuracy: 0.9428\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.94611\n",
      "1050/1050 - 13s - loss: 0.0587 - accuracy: 0.9766 - val_loss: 0.1909 - val_accuracy: 0.9369\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.94611\n",
      "1050/1050 - 13s - loss: 0.0586 - accuracy: 0.9770 - val_loss: 0.2132 - val_accuracy: 0.9419\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.94611\n",
      "1050/1050 - 13s - loss: 0.0557 - accuracy: 0.9778 - val_loss: 0.1850 - val_accuracy: 0.9403\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.94611\n",
      "1050/1050 - 13s - loss: 0.0566 - accuracy: 0.9773 - val_loss: 0.2092 - val_accuracy: 0.9408\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.94611\n",
      "1050/1050 - 13s - loss: 0.0543 - accuracy: 0.9775 - val_loss: 0.2389 - val_accuracy: 0.9411\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.94611\n",
      "1050/1050 - 13s - loss: 0.0531 - accuracy: 0.9789 - val_loss: 0.2309 - val_accuracy: 0.9397\n"
     ]
    }
   ],
   "source": [
    "#Running and Saving model\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "filepath = \"model/pretrained/spp_featurenet.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,\n",
    "                             save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "history = model.fit(x_train, y_train, batch_size=16, epochs= 30, verbose=2,\n",
    "                    validation_data=(x_val,y_val), shuffle=True, class_weight=None,\n",
    "                    sample_weight=None, initial_epoch=0, steps_per_epoch=None, \n",
    "                    validation_steps=None, validation_freq=1, max_queue_size=10,\n",
    "                    workers=1,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the model\n",
    "\n",
    "from  tensorflow.keras.models import load_model\n",
    "model = load_model(\"model/pretrained/spp_featurenet.h5\",custom_objects={'SpatialPyramidPooling': SpatialPyramidPooling})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a temperory model for spp output\n",
    "\n",
    "from  tensorflow.keras.models import Model\n",
    "layer_name = 'my_layer'\n",
    "intermediate_layer_model = Model(inputs=model.input,outputs=model.get_layer('spatial_pyramid_pooling').output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3600/3600 [09:57<00:00,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for  3600 testing files is  0.9283333333333333\n",
      "Top 5 accuracy for  3600 testing files is  0.9852777777777778\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Finding accuracy on test set\n",
    "spp_train = intermediate_layer_model.predict(x_train)\n",
    "\n",
    "top5_acc =0\n",
    "top1_acc =0\n",
    "top5_lbl = list()\n",
    "sim_list = list()\n",
    "null_index = list()\n",
    "classes = 24\n",
    "\n",
    "for i in tqdm (range(0,len(x_test))):\n",
    "    sim_list.clear()\n",
    "    #test_feat = spp_test[i]\n",
    "    test_feat = tf.reshape(x_test[i],[1,max_val,32,1])\n",
    "    spp_test = intermediate_layer_model.predict(test_feat)\n",
    "    y_t = y_test[i]\n",
    "    for j in range(0,classes):\n",
    "        if(y_t[j].numpy()==1.0):\n",
    "            test_lbl = Y_list[j]  \n",
    "    for k in range(0,len(x_train)):  \n",
    "        #train_feat = tf.reshape(x_train[i],[1,max_val,32,1])\n",
    "        sim_list.append(abs(np.linalg.norm(spp_train[k]-spp_test)))\n",
    "    id = list(range(0,len(x_train)))\n",
    "    Sim_models_id = [x for _,x in sorted(zip(sim_list,id))]\n",
    "    top5 = (Sim_models_id[0:5])\n",
    "    top5_lbl.clear()\n",
    "    for l in range(0,5): \n",
    "        yi = y_train[top5[l]]\n",
    "        for m in range(0,classes):\n",
    "            if ((yi[m].numpy())==1.0):\n",
    "                top5_lbl.append(Y_list[m])\n",
    "    if(test_lbl in top5_lbl):\n",
    "        top5_acc+=1\n",
    "        \n",
    "    if (top5_lbl):\n",
    "        if(test_lbl == top5_lbl[0]):\n",
    "            top1_acc+=1\n",
    "    else:\n",
    "        null_index.append(i)\n",
    "        \n",
    "print(\"Accuracy for \",len(x_test),\"testing files is \",top1_acc/len(x_test))\n",
    "print(\"Top 5 accuracy for \",len(x_test),\"testing files is \",top5_acc/len(x_test))\n",
    "print(len(null_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving similar features from the dataset for a sample file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading stl dataset paths \n",
    "\n",
    "db_folder = \"data/stl\"\n",
    "os.path.abspath(db_folder)\n",
    "ind = 0\n",
    "stl_file_path = list()\n",
    "sub_folders = os.listdir(db_folder)\n",
    "for sub_folder in sub_folders:\n",
    "        sub_folder_path = os.path.join(db_folder, sub_folder)\n",
    "        stl_files = os.listdir(sub_folder_path)\n",
    "        for stl_file in stl_files:\n",
    "            if stl_file.endswith(\".STL\"):\n",
    "                stl_file_path.append(os.path.join(sub_folder_path, stl_file))\n",
    "                ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spp_out(feat):\n",
    "    test_feat = tf.reshape(feat,[1,max_val,32,1])\n",
    "    spp_test = intermediate_layer_model.predict(test_feat)\n",
    "    return spp_test    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test file\n",
      " \n",
      "ID:\t 1990 \tFamily:\t 20_v_circular_end_blind_slot\n"
     ]
    }
   ],
   "source": [
    "#test file\n",
    "\n",
    "test_id = 1990\n",
    "print(\"Test file\\n\",\"\\nID:\\t\",test_id,\"\\tFamily:\\t\",file_names[test_id])\n",
    "test_feat = zero_pad(features[test_id])\n",
    "spp_test_feat = get_spp_out(test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing similaity between one test file and all the features individually\n",
    "\n",
    "n_files = len(features)\n",
    "\n",
    "sim_list = list()\n",
    "for i in range(0,n_files):\n",
    "    if(i!=test_id):\n",
    "        feat = zero_pad(features[i])\n",
    "        feat = tf.reshape(feat,[1,max_val,32,1])\n",
    "        spp_feat = intermediate_layer_model.predict(feat)\n",
    "        sim_list.append(abs(np.linalg.norm(spp_feat - spp_test_feat)))\n",
    "    else:\n",
    "        sim_list.append(float(\"inf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1256, 1143, 1030, 1284, 1406]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = list(range(0,n_files))\n",
    "\n",
    "Similar_models_id = [x for _,x in sorted(zip(sim_list,id))]\n",
    "top_5 = (Similar_models_id[0:5])\n",
    "top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test file\n",
      " \n",
      "ID:\t 1990 \tFamily:\t 20_v_circular_end_blind_slot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/environments/s4engine/lib/python3.8/site-packages/jupyter_client/session.py:716: UserWarning: Message serialization failed with:\n",
      "Out of range float values are not JSON compliant\n",
      "Supporting this message is deprecated in jupyter-client 7, please make sure your message is JSON-compliant\n",
      "  content = self.pack(content)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e8220af432443979c676472d52db1fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), Renderer(background='#cccc88', background_opacity=0.0, camera=PerspectiveCamera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-5 similar models and their IDs\n",
      "\n",
      "ID:\t 1256 \tFamily:\t 20_v_circular_end_blind_slot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922f1679892a4e308b08ec08097ec892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), Renderer(background='#cccc88', background_opacity=0.0, camera=PerspectiveCamera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:\t 1143 \tFamily:\t 20_v_circular_end_blind_slot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae75a818b5643fa98840f2206718772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), Renderer(background='#cccc88', background_opacity=0.0, camera=PerspectiveCamera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:\t 1030 \tFamily:\t 20_v_circular_end_blind_slot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c8ab6dd78c45ad8f01d2452534ddba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), Renderer(background='#cccc88', background_opacity=0.0, camera=PerspectiveCamera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:\t 1284 \tFamily:\t 20_v_circular_end_blind_slot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86a9e9c3d9b24ac0beff95ef73f7d02b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), Renderer(background='#cccc88', background_opacity=0.0, camera=PerspectiveCamera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:\t 1406 \tFamily:\t 20_v_circular_end_blind_slot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2766ad0998f4818991b786424aa872f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), Renderer(background='#cccc88', background_opacity=0.0, camera=PerspectiveCamera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualiztion of the CAD files\n",
    "from solid import*\n",
    "import viewscad\n",
    "r = viewscad.Renderer()\n",
    "print(\"Test file\\n\",\"\\nID:\\t\",test_id,\"\\tFamily:\\t\",file_names[test_id])\n",
    "r.render_stl(stl_file_path[test_id])\n",
    "print(\"\\nTop-5 similar models and their IDs\\n\")\n",
    "for i in range(0,5): \n",
    "    yi = file_names[top_5[i]]\n",
    "    print(\"ID:\\t\",top_5[i],\"\\tFamily:\\t\",yi)\n",
    "    r.render_stl(stl_file_path[top_5[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s4engine",
   "language": "python",
   "name": "s4engine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
