{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085e0c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset if you haven't already\n",
    "\n",
    "!wget -O data/dataset.rar https://github.com/madlabub/Machining-feature-dataset/blob/master/dataset.rar?raw=true\n",
    "!unrar x data/dataset.rar data/\n",
    "!rm -r data/dataset.rar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7569867",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import open3d as o3d\n",
    "from model.resunet import ResUNetBN2C\n",
    "from util.visualization import get_colored_point_cloud_feature\n",
    "from numpy import linalg as LA\n",
    "from util.feature_extraction import stl2ply_convert, feature_extract\n",
    "#from util.feature_extraction import get_features\n",
    "from util.misc import sort_list, zero_pad\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17c97e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the pretrained fcgf model\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "checkpoint = torch.load('model/pretrained/model_32.pth', map_location=device)\n",
    "model = ResUNetBN2C(1,32, normalize_feature=True, conv1_kernel_size=checkpoint[\"config\"][\"conv1_kernel_size\"], D=3)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556a0482",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e672a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the data is available is STL format\n",
    "\n",
    "stl_folder = \"data/stl\"\n",
    "\n",
    "ply_folder = \"data/ply\"\n",
    "\n",
    "if not os.path.exists(ply_folder):\n",
    "    os.makedirs(ply_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01adbe1c",
   "metadata": {},
   "source": [
    "### Convertion to PLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2454517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting .stl files to .ply format for feature extraction\n",
    "\n",
    "stl2ply_convert(stl_folder,ply_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b46a09",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbea8cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/kamal/shape_search_new/util/feature_extraction.py:179: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  coords = torch.tensor(coords, dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "#Feature Extraction from .ply files\n",
    "\n",
    "file_names, file_paths, features = feature_extract(ply_folder, model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8bd506c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9_triangular_pocket\n",
      "20_v_circular_end_blind_slot\n",
      "11_circular_end_pocket\n",
      "4_rectangular_passage\n",
      "21_h_circular_end_blind_slot\n",
      "0_Oring\n",
      "16_2sides_through_step\n",
      "2_blind_hole\n",
      "23_6sides_pocket\n",
      "7_rectangular_through_slot\n",
      "6_triangular_through_slot\n",
      "17_slanted_through_step\n",
      "22_6sides_passage\n",
      "8_rectangular_blind_slot\n",
      "1_through_hole\n",
      "5_circular_through_slot\n",
      "3_triangular_passage\n",
      "15_rectangular_through_step\n",
      "19_round\n",
      "14_rectangular_blind_step\n",
      "18_chamfer\n",
      "13_circular_blind_step\n",
      "12_triangular_blind_step\n",
      "10_rectangular_pocket\n"
     ]
    }
   ],
   "source": [
    "#Printing the different classes\n",
    "unique_list = []\n",
    "\n",
    "# traverse for all elements\n",
    "for x in file_names:\n",
    "    # check if exists in unique_list or not\n",
    "    if x not in unique_list:\n",
    "        unique_list.append(x)\n",
    "\n",
    "for x in unique_list:\n",
    "    print(x)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "983cf4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is adviced to pickle the extracted features to save time in execution next time\n",
    "\n",
    "data = [file_names, file_paths, features]\n",
    "with open(\"data/names_paths_features_featurenet.dat\", \"wb\") as f:\n",
    "    pickle.dump(data, f) \n",
    "    \n",
    "#Unpickling the features\n",
    "\n",
    "with open(\"data/names_paths_features_featurenet.dat\", \"rb\") as f:\n",
    "    file_names, file_paths, features = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14c5cd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of a sample feature vector: (14, 32)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of a sample feature vector:\",features[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7e13c0",
   "metadata": {},
   "source": [
    "### Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d75d8a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_files = len(features)\n",
    "\n",
    "tested_files = list()\n",
    "sim_list = list()\n",
    "sorted_list = list()\n",
    "check_1 = 0\n",
    "check_5 = 0\n",
    "for i in range(0,N_files):\n",
    "    test_feature = features[i]\n",
    "    tested_files.clear()\n",
    "    sim_list.clear()\n",
    "    for j in range(0,N_files):\n",
    "        if file_names[j] not in tested_files:\n",
    "            tested_files.append(file_names[j])\n",
    "            db_feature = features[j]\n",
    "            # finding out the similarity between features\n",
    "            sim_list.append(abs(LA.norm(test_feature, 'fro') - LA.norm(db_feature, 'fro')))\n",
    "    sorted_list = sort_list(file_names, sim_list)\n",
    "    check_1 += (file_names[i] ==  sorted_list[0])\n",
    "    if file_names[i] in sorted_list[0:4]:\n",
    "        check_5 += 1     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "282ab3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 Accuracy with Frobenius Norm is \t 0.847875\n",
      "Accuracy with Frobenius Norm is is \t 0.311\n"
     ]
    }
   ],
   "source": [
    "print(\"Top-5 Accuracy with Frobenius Norm is \"+\"\\t\",check_5/N_files)\n",
    "print(\"Accuracy with Frobenius Norm is is \"+\"\\t\",check_1/N_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd51d77",
   "metadata": {},
   "source": [
    "We can observe the inability of Frobenius norm by itslef to serve as a good similarity measure.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s4engine",
   "language": "python",
   "name": "s4engine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
